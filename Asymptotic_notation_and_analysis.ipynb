{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Asymptotic notation and analysis",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZj2P9CGMJ13XDrmGHMxI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/AHCVS_Notes/blob/main/Asymptotic_notation_and_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Efficienct algorithm vs fast computer "
      ],
      "metadata": {
        "id": "WaYf24f7N9tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Efficiency \n",
        "  * The **amount of work done per some time**.\n",
        "  * Two aspects \n",
        "    1. Size/ amount of work done \n",
        "      * Can be measured by taking a constant time (amount done/ second)\n",
        "    2. Time \n",
        "\n",
        "* Efficient algorithm (Relative)\n",
        "  * If Two algorithms (A, B) solve the same problem, then we can say **algorithm** A is efficent if it **takes less number of steps** to solve the problem when compared to B.\n",
        "    * E.g. \n",
        "      1. Algorithm  A - n work to complete task \n",
        "      2. Algorithm B - n^2  work to complete same task\n",
        "\n",
        "      => Algorithm A is efficient\n",
        "\n",
        "* Computation power of computers\n",
        "  * Computers that can **handle higher number** of instruction per second.\n",
        "  \n",
        "* As computation power increases \n",
        "  * It is the **algorithm efficiency that really determines**\n",
        "    * **Running time efficiency** with increase in problem size (input size) \n",
        "    * **Efficiency of amount of work/size of problem** that can be solved.   \n",
        "  * E.g. http://www.cs.ox.ac.uk/files/7065/asymptotics.pdf\n",
        "    * As computation power (steps per second) is increased and complexity (steps of algorithm) is worsend  (n,n^2, n^3, 2^n), there is \n",
        "      * Marginal increase in the amount of work (size) done per unit time\n",
        "      * Large decrease in the speed (Time)"
      ],
      "metadata": {
        "id": "NF6PtDDRN-QC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asymptotic notation"
      ],
      "metadata": {
        "id": "EH7Yhtm3J5Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Why ?\n",
        "  * Analyze algorithms\n",
        "  * Algorithm can be considered as a function with certain number of inputs \n",
        "    * *f(n)* \n",
        "      * n - input size\n",
        "      * f - function \n",
        "\n",
        "* What ?\n",
        "  * Asymptotic Notations are **notations** that allow us to **analyze an algorithm's running time** by identifying its **behavior as the input size for the algorithm increases to n**. http://www.cs.ox.ac.uk/files/7065/asymptotics.pdf\n",
        "\n",
        "  * 3 classes of notations \n",
        "    1. Big O (**Aymptotic upper bound**)\n",
        "      * An algorithm takes **atmost/less than or equal to** big O(-) time\n",
        "    2. Big Omega (**Asymptotic lower bound**)\n",
        "      * An algorithm takes **atleast /greator than or equal to** big omega O(-) time\n",
        "    3. Big Theta (**Asymptotic tight bound** - between lower and upper bound)\n",
        "      * An algorithm takes **not less than and not greater than** big theta (-) time\n",
        "\n",
        "* How ?\n",
        "  * Asymptotic analysis - Classifying functions (algorithm) into a 3 classes \n",
        "    * Ignore lower order terms\n",
        "    * Ignore constants \n",
        "\n"
      ],
      "metadata": {
        "id": "VmXVJ9TvJ-C9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asymptotic analysis \n",
        "\n",
        "Source : https://www2.cs.arizona.edu/classes/cs345/summer14/files/bigO.pdf"
      ],
      "metadata": {
        "id": "YTBpdu82Qd-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing algorithms and classifying them into asynptotic upper lower and tight bounds.\n",
        "\n",
        "1. Big O \n",
        "  * An algorithm/function **f(n) is O(g(n))** - g(n) being the **asymptotic upper bound iff**\n",
        "    * For large enough values of n, the running time is atmost g(n)  \n",
        "        `f(n) <= c.g(n) for some constant c>0`\n",
        "2. Big Omega \n",
        "  * A function **f(n) is Omega(g(n))** - g(n) being the **asymptotic lower bound iff**\n",
        "    * For large enough values of n, the running time is atleast g(n)\n",
        "        \n",
        "        `f(n) >= c.g(n) for some constant c>0`\n",
        "3. Big Theta \n",
        "  * A function **f(n) is Theta(g(n))** - g(n) being the **asymptotic tight bound iff**\n",
        "    * For large enough values of n, the running time is between constants c1,c2 such that\n",
        "     \n",
        "      `c1.g(n) <= f(n) <= c2.g(n)`\n",
        "\n"
      ],
      "metadata": {
        "id": "4lCZgbL9YU60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big O notation "
      ],
      "metadata": {
        "id": "vAn7FSOg1XDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bJmyAsb51huK"
      }
    }
  ]
}